{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc7aa419",
   "metadata": {},
   "source": [
    "# Cosmological structure\n",
    "\n",
    "Here, we use `twinLab` to create an emulator for the statistical properties of the distribution of structure in the Universe.\n",
    "\n",
    "The large-scale distribution of billions of galaxies contains a wealth of information about the origin, expansion, and contents of the Universe. For example, the galaxy distribution is sensitive to the amounts of dark energy and dark matter, the current and historial expansion speed, and the process of inflation that occurred soon after the big bang and which seeded the diverse array of cosmological structure, including all galaxies, stars and planets, that we see today. Galaxies exist in dense clumps, called groups, clusters, super clusters, depending on the number, at the nodes of the density distribution. The underlying density is governed by the dynamics and properties of dark matter, which defines a skeleton along which galaxies flow and eventually cluster.\n",
    "\n",
    "![N-body simulation](resources/images/density.png)\n",
    "\n",
    "To extract cosmological information from the galaxy distribution requires precise models of the statistical properties of the distribution as a function of the underlying parameters. Analytical theories, developed over the last 30 years, work at early times and on extremely large scales, where perturbations to the mean density are small. However, on the (comparatively small) scale of galaxies, the perturbations are huge and modelling their distribution can only be accurately achieved using expensive $N$-body simulations (the image above shows a slice of density through one such simulation). High-fidelity simulations can take up to a month to run distributed across tens of thousands of cores on the top super computers in the world. It is impractical to run accurate simulations at all points in parameter space, especially since the parameter-space of models under investigation is always expanding. In modern cosmology this includes the space of exotic dark energy models, beyond-Einstein gravity theories, and non-standard particle physics models for dark matter and neutrinos.\n",
    "\n",
    "In this example, we use `twinLab` to create an emulator for the matter power spectrum, a statistical quantity that contains a subset of the possible information from the clustering distribution of galaxies. The power spectrum can both be computed via simulation and measured in observational datasets. The training of the `twinLab` emulator is performed online (in the cloud) and is completed in a matter of minutes. Once trained, the emulator can be used for extremely rapid power-spectrum evaluation across parameter space in a way that interpolates and extrapolates reasonably. The major benefit of using `twinLab` is that we get an accurate estimate of our model uncertainty for free, so that we know exactly how much we should trust our trained surrogate. The model is trained on approximate simulation data that occupy a Latin-hypercube distribution across five parameters of interest to cosmologists. The model can be rapidly retrained if necessary, and additional parameters can be incorporated if desired."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "713fe7a1",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "First, we import the libraries and the `twinLab` client with. Note that We need to supply our credentials to use `twinLab`, and these should be in a `.env` file in the project root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# twinLab\n",
    "import twinlab as tl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6942ac1f",
   "metadata": {},
   "source": [
    "Ensure that the correct group and user names are reported, these are taken from your `.env` file, which should be present in the root directory of the repository (you can construct this from `.env.example`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6a73e0a",
   "metadata": {},
   "source": [
    "Set some parameters for training the machine-learning campaign..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Campaign\n",
    "CAMPAIGN_ID = \"cosmology\"\n",
    "DATASET_ID = \"cosmology\"\n",
    "\n",
    "# Data options\n",
    "POWER_RATIO = True    # We are going to learn the ratio of the non-linear to linear spectrum\n",
    "POWER_LOG = True      # We are going to learn the log of the (ratio of the) power spectrum\n",
    "POWER_LATIN = True    # We are taking data where the training points are Latin hypercube sampled\n",
    "TRAINING_RATIO = 1.   # Use all training data\n",
    "SVD_VARIANCE = 0.9999 # Retain 99.99% of the variance in the SVD/PCA decomposition of the data\n",
    "\n",
    "# Data files\n",
    "TRAINING_FILEBASE = \"cosmo\" \n",
    "EVALUATION_FILEBASE = \"eval\"\n",
    "GRID_DATA = \"grid.csv\"\n",
    "NK = 100 # Number of wave-number values (pre-determined by the data file)\n",
    "\n",
    "# Directories\n",
    "CAMPAIGN_DIR = os.path.join(\"resources\", \"campaigns\", \"cosmology\")\n",
    "DATASETS_DIR = os.path.join(\"resources\", \"datasets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f5aa377",
   "metadata": {},
   "source": [
    "...and do some minor calculations to sort the file names out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378bdc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffixes for data files\n",
    "latin_thing = '_latin' if POWER_LATIN else ''\n",
    "ratio_thing = '_ratio' if POWER_RATIO else ''\n",
    "log_thing = '_log' if POWER_LOG else ''\n",
    "\n",
    "# Construct training and evaluation data file names\n",
    "TRAINING_DATA = TRAINING_FILEBASE+latin_thing+ratio_thing+log_thing+\".csv\"\n",
    "EVALUATION_DATA = EVALUATION_FILEBASE+ratio_thing+log_thing+\".csv\"\n",
    "\n",
    "# File paths\n",
    "DATASET_PATH = os.path.join(DATASETS_DIR, TRAINING_DATA)\n",
    "EVALUATION_PATH = os.path.join(CAMPAIGN_DIR, EVALUATION_DATA)\n",
    "GRID_PATH = os.path.join(CAMPAIGN_DIR, GRID_DATA)\n",
    "\n",
    "# Write to screen\n",
    "print(f\"Grid........ {GRID_PATH}\")\n",
    "print(f\"Dataset..... {DATASET_PATH}\")\n",
    "print(f\"Evaluate.... {EVALUATION_PATH}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8fca977",
   "metadata": {},
   "source": [
    "### Data upload\n",
    "\n",
    "Now we can upload the training dataset to the `twinLab` cloud..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a059f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.upload_dataset(DATASET_PATH, DATASET_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9ff52fa",
   "metadata": {},
   "source": [
    "...and list which datasets are available to train with (and check that our dataset uploaded)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b55e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tl.list_datasets()\n",
    "pprint(datasets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9973bdd",
   "metadata": {},
   "source": [
    "...and query the freshly-uploaded dataset to provide a statistical summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tl.query_dataset(DATASET_ID)\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d02ebd9a",
   "metadata": {},
   "source": [
    "### Training parameters\n",
    "\n",
    "Here we set the emulator training parameters. In this example, we will train a functional Gaussian Process to act as a surrogate model for the power spectrum. We specify five cosmological parameters as inputs (in that, we wish to know the power spectrum as a function of these 5 parameters) and output the power spectrum at 100 pre-determined (log-spaced) wave-numbers. The data-points are obviously very strongly correlated, because the output is a function where the value of the power at each wave-number depends very strongly on the value of the power at neighbouring wave-numbers (the function is smooth). A functional Gaussian Process decomposes the set of training data into a set of basis functions that is determined by the data themselves. The sum of these functions then capture the overall shapes of all power spectra, and the exact coefficients used in the sum are then the numbers that are learned (as a function of cosmological parameters inputs) when the Gaussian Process is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b950ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmological_parameters = [\"Omega_c\", \"Omega_b\", \"h\", \"ns\", \"w0\"] # We will take these cosmological parameters as input\n",
    "wavenumber_columns = [f\"k{i}\" for i in range(NK)] # We will try to learn P(k) at these wavenumbers\n",
    "params = { # Parameters file for twinLab\n",
    "    \"dataset_id\": DATASET_ID,\n",
    "    \"inputs\": cosmological_parameters,\n",
    "    \"outputs\": wavenumber_columns,\n",
    "    \"decompose_outputs\": True,\n",
    "    \"output_explained_variance\": SVD_VARIANCE,\n",
    "    \"train_test_ratio\": TRAINING_RATIO,\n",
    "}\n",
    "pprint(params, compact=True, sort_dicts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76b083f8",
   "metadata": {},
   "source": [
    "### Surrogate model training\n",
    "\n",
    "Now we can train the emulator. One choice that we have made here is to predict the logarithm of the power spectrum, rather than the power spectrum itself. This makes sense because our target is a positive-definite quantity that spans many orders of magnitude, and also because the target *accuracy* that we are interested in is the ratio of the model prediction to the truth (rather than the difference), and predicting the logarithm of the power spectrum gives us a Gaussian error distribution on this ratio (but would give us a skewed log-normal distribution on the difference).\n",
    "\n",
    "Training a Gaussian process simply means adapting the parameters of the kernel to best model the training data, which is done by `twinLab` using gradient-descent techniques on coefficients of the kernel. This kernel then parametrises the covariance matrix between data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.train_campaign(params, CAMPAIGN_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c75b9857",
   "metadata": {},
   "source": [
    "Check that our campaign has trained with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaigns = tl.list_campaigns()\n",
    "pprint(campaigns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f359f0d9",
   "metadata": {},
   "source": [
    "View a summary of the trained emulator with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3911b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = tl.query_campaign(CAMPAIGN_ID)\n",
    "pprint(query, compact=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b681e3a",
   "metadata": {},
   "source": [
    "From this summary of training, we see that the 100 power spectrum data points have been reduced to 9 principal components, which means that our Gaussian Process needs to predict 9 numbers, rather than 100. These 9 numbers capture 99.99% of the variance in the target function, or almost all of the information that is available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "106a9c99",
   "metadata": {},
   "source": [
    "We can now make predictions using trained emulator, this is now for previously unseen sets of cosmological parameters. He we also make \"predictions\" using the emulator for data that the emulator was trained upon. This allows us to see the difference between the performance of the emulator on seen data and on unseen data. One might think that the emulator should be \"perfect\" when evaluated on training examples, after all these were \"seen\" by the machine-learning algorithm. Later, we shall see that this is not so for the `twinLab` implementation of Gaussian Processes, which is because allowing a small amount of wiggle room for the predictions about the training data points tends to produce a better model fit over all data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd70a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_mean, df_eval_std = tl.predict_campaign(EVALUATION_PATH, CAMPAIGN_ID)\n",
    "df_train_mean, df_train_std = tl.predict_campaign(DATASET_PATH, CAMPAIGN_ID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c97b226",
   "metadata": {},
   "source": [
    "Now we read in the evaluation data and the grid of wave-number values on which to evaluate the power spectrum, which are only used for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATASET_PATH)\n",
    "df_grid = pd.read_csv(GRID_PATH)\n",
    "df_eval = pd.read_csv(EVALUATION_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d02e9d9",
   "metadata": {},
   "source": [
    "### Plotting results\n",
    "\n",
    "Now we can plot the accuracy of the trained emulator as a function of wavenumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee83b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy statistics\n",
    "if POWER_LOG: # Note that the difference is appropriate here because the data may be log\n",
    "    accuracy_eval = (df_eval_mean[wavenumber_columns]-df_eval[wavenumber_columns]).std()\n",
    "    accuracy_train = (df_train_mean[wavenumber_columns]-df_train[wavenumber_columns]).std()\n",
    "else:\n",
    "    accuracy_eval = (df_eval_mean[wavenumber_columns]/df_eval[wavenumber_columns]-1.).std()\n",
    "    accuracy_train = (df_train_mean[wavenumber_columns]/df_train[wavenumber_columns]-1.).std()\n",
    "\n",
    "plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "# Accuracy of model\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df_grid.iloc[0].values, 100.*accuracy_eval, label='Evaluation data')\n",
    "plt.plot(df_grid.iloc[0].values, 100.*accuracy_train, label='Training data')\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "plt.ylim(bottom=0.)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy of preicted error\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(df_grid.iloc[0].values, accuracy_eval/df_eval_std.iloc[0].values)\n",
    "plt.plot(df_grid.iloc[0].values, accuracy_train/df_train_std.iloc[0].values)\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(r\"Fourier wavenumber [$h$ Mpc$^{-1}$]\")\n",
    "plt.axhline(1., color=\"k\", linestyle=\":\", lw=0.5)\n",
    "plt.ylabel(\"Relative accuracy\")\n",
    "plt.ylim((0., 2.))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28929de0",
   "metadata": {},
   "source": [
    "We see that the emulator achieves an RMS error of 0.2% on the training data, which is excellent. On the unseen test data it still achieves an RMS error of less than one percent, which is still excellent, and acceptable for modern cosmological applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04b455f2",
   "metadata": {},
   "source": [
    "Now we can plot the performance of the emulator for the raw data. In investigating this problem, we found that more accurate emulators were produced when they were trained to predict the ratio of the non-linear power spectrum to the linear power spectrum. The non-linear power spectrum is hard to predict, and requires high-resolution, expensive $N$-body simulations to be run and the non-linear spectrum to be measured from these. Depending on the simulation resolution, these can take many weeks to run and consume tens-of-thousands of CPU hours. The linear spectrum, on the other hand, can be evaluated in a few seconds on a laptop. It seems that the ratio of these quantities is easier to emulate, presumably because much of the structure in the non-linear spectrum is similar to that in the underlying linear spectrum. \n",
    "\n",
    "Disadvantages of this approach are that the linear spectrum is still required to make predictions, and the few second evaluation time is far greater than the milliseconds that it takes to make predictions using the emulator. A further disadvantage of not emulating the non-linear power spectrum directly is that the emulator itself is naturally differentiable (with respect to input 'cosmological' parameters), and this would allow for advanced inference techniques such as Hamiltonian Monte-Carlo to be used. Unfortunately the linear spectrum (evaluated via Boltzmann codes) is not differentiable, thus we lose this differentiability if we emulate only the ratio, where we still require the linear spectrum to construct the full non-linear prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff61305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "nsig = [1, 2]  # sigma errors to plot\n",
    "mfac = 10.  # Factor to inflate error bars by\n",
    "alpha_data = 0.5\n",
    "alpha_model = 0.5\n",
    "color_model = \"C0\"\n",
    "plot_mean = True\n",
    "plot_band = True\n",
    "npow = 5\n",
    "\n",
    "# Plot power\n",
    "plt.subplots(1, npow, figsize=(npow*3.5, 3.), sharex=True, sharey=True)\n",
    "grid = df_grid.iloc[0].values\n",
    "for i in range(npow):\n",
    "    plt.subplot(1, npow, i+1)\n",
    "    if POWER_RATIO:\n",
    "        plt.axhline(1., color=\"black\", lw=0.5)\n",
    "    eval = df_eval[wavenumber_columns].iloc[i].values\n",
    "    mean = df_eval_mean.iloc[i].values\n",
    "    err = df_eval_std.iloc[i].values\n",
    "    if POWER_LOG:\n",
    "        eval, mean = np.exp(eval), np.exp(mean)\n",
    "    label = \"Evaluation data\" if i==0 else None\n",
    "    plt.plot(grid, eval, color=\"black\", alpha=alpha_data, label=label)\n",
    "    if plot_band:\n",
    "        for sig in nsig:\n",
    "            if POWER_LOG:\n",
    "                ymin, ymax = np.exp(-mfac*sig*err), np.exp(mfac*sig*err)\n",
    "                ymin, ymax = mean*ymin, mean*ymax\n",
    "            else:\n",
    "                ymin, ymax = -mfac*sig*err, mfac*sig*err\n",
    "                ymin, ymax = mean+ymin, mean+ymax\n",
    "            lab = f\"Model (error inflated by {mfac})\" if mfac != 1. else \"Model\"\n",
    "            label = lab if sig==nsig[0] else None\n",
    "            plt.fill_between(grid, ymin, ymax, color=color_model, lw=0., alpha=alpha_model/sig, label=label)\n",
    "    if plot_mean:\n",
    "        label  = \"Model\" if not plot_band else None\n",
    "        plt.plot(grid, mean, color=color_model, alpha=alpha_model, label=label)\n",
    "    plt.xlabel(r\"Fourier wavenumber [$h$ Mpc$^{-1}$]\")\n",
    "    plt.xscale(\"log\")\n",
    "    if i==0: \n",
    "        if POWER_RATIO:\n",
    "            plt.ylabel(r\"Power ratio with linear\")\n",
    "        else:\n",
    "            plt.ylabel(r\"Power spectrum [$(h^{-1}\\mathrm{Mpc})^3$]\")\n",
    "        plt.legend()\n",
    "    plt.yscale(\"log\")\n",
    "    if not POWER_RATIO:\n",
    "        plt.ylim((1e0, 1e5))\n",
    "    else:\n",
    "        plt.ylim((0.5, 100.))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "384dea95",
   "metadata": {},
   "source": [
    "We see the model predictions and the associated error bands, although the error bands are too small to be seen unless we inflate them by a factor of 10. This is partly due to the good performance of our model, but also partly due to the log scale used to display the power spectrum. Note that the error bars are symmetric given that we used a log scale on the $y$ axis, but they would not be symmetric if we used a linear scale. This is due to our decision to use our emulator to predict the logarithm of the power spectrum, so the errors are Gaussian in log space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "145b6038",
   "metadata": {},
   "source": [
    "Finally, we plot the residuals between model predictions and the truth for a random selection of independent examples from training (seen by the model already; orange) and evaluation (unseen by the model; blue) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nsig = [1, 2]\n",
    "alpha_data = 0.5\n",
    "alpha_model = 0.5\n",
    "color_model = \"C0\"\n",
    "plot_train = True\n",
    "alpha_train = 0.5\n",
    "color_train = \"C1\"\n",
    "dr = 3.\n",
    "plot_band = True\n",
    "plot_mean = True\n",
    "ncos = 10\n",
    "nrow = 2\n",
    "\n",
    "# Calculations\n",
    "ncol = ncos//nrow\n",
    "\n",
    "# Plot\n",
    "grid = df_grid.iloc[0].values\n",
    "plt.subplots(nrow, ncol, figsize=(3*ncol, 2.5*nrow), sharex=True, sharey=True)\n",
    "for i in range(ncos):\n",
    "    plt.axhline(0., color=\"black\", lw=1)\n",
    "    plt.subplot(nrow, ncol, i+1)\n",
    "    eval = df_eval[wavenumber_columns].iloc[i].values\n",
    "    eval_mean = df_eval_mean.iloc[i].values\n",
    "    eval_err = df_eval_std.iloc[i].values\n",
    "    train = df_train[wavenumber_columns].iloc[i].values\n",
    "    train_mean = df_train_mean.iloc[i].values\n",
    "    train_err = df_train_std.iloc[i].values\n",
    "    if POWER_LOG:\n",
    "        eval, eval_mean = np.exp(eval), np.exp(eval_mean)\n",
    "        train, train_mean = np.exp(train), np.exp(train_mean)\n",
    "    if plot_band:\n",
    "        for sig in nsig:\n",
    "            if POWER_LOG:\n",
    "                ymin, ymax = np.exp(-sig*eval_err), np.exp(sig*eval_err)\n",
    "                ymin, ymax = 100.*((eval_mean*ymin)/eval-1.), 100.*((eval_mean*ymax)/eval-1.)\n",
    "            else:\n",
    "                ymin, ymax = -sig*eval_err, sig*eval_err\n",
    "                ymin, ymax = 100.*((eval_mean+ymin)/eval-1.), 100.*((eval_mean+ymax)/eval-1.)\n",
    "            label = \"Model on test data\" if sig==nsig[0] else None\n",
    "            plt.fill_between(grid, ymin, ymax, color=color_model, lw=0, alpha=alpha_model/sig, label=label)\n",
    "            if plot_train:\n",
    "                if POWER_LOG:\n",
    "                    ymin, ymax = np.exp(-sig*train_err), np.exp(sig*train_err)\n",
    "                    ymin, ymax = 100.*((train_mean*ymin)/train-1.), 100.*((train_mean*ymax)/train-1.)\n",
    "                else:\n",
    "                    ymin, ymax = -sig*train_err, sig*train_err\n",
    "                    ymin, ymax = 100.*((train_mean+ymin)/train-1.), 100.*((train_mean+ymax)/train-1.)\n",
    "                label = \"Model on training data\" if sig==nsig[0] else None\n",
    "                plt.fill_between(grid, ymin, ymax, color=color_train, lw=0, alpha=alpha_train/sig, label=label)\n",
    "    if plot_mean:\n",
    "        label = \"Model on test data\" if not plot_band else None\n",
    "        y = 100.*(eval_mean/eval-1.)\n",
    "        plt.plot(grid, y, color=color_model, alpha=alpha_model, label=label)\n",
    "        if plot_train:\n",
    "            label = \"Model on training data\" if not plot_band else None\n",
    "            y = 100.*(train_mean/train-1.)\n",
    "            plt.plot(grid, y, color=color_train, alpha=alpha_train, label=label)\n",
    "    if i//ncol==nrow-1: plt.xlabel(r\"$k/h\\mathrm{Mpc}^{-1}$\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlim((grid[0], grid[-1]))\n",
    "    if i%ncol==0: plt.ylabel(r\"$P_\\mathrm{model}(k)/P_\\mathrm{truth}(k)-1$ [%]\")\n",
    "    plt.ylim((-dr, dr))\n",
    "    if i==0: plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e217a4",
   "metadata": {},
   "source": [
    "We see that the predictions are generally excellent on the training data, although they are not perfect (and one might assume they would be) for the reasons mentioned above. On the test data, we still see good performance, but the error creeps up to around a few per-cent for some sets of cosmological parameters. From the previous plots we also note that the emulator is slightly conservative in its estimate of error, over-predicting the error bound by a factor of around two. However, here we see that the emulator-predicted error is usually a good indication of actual uncertainty (i.e., the model error is larger when the model is more wrong, which is good). The error-bound can therefore be taken to be a conservative estimate of the error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edc41b52",
   "metadata": {},
   "source": [
    "Finally, we can delete the trained emulator and dataset if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6e659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.delete_campaign(CAMPAIGN_ID)\n",
    "tl.delete_dataset(DATASET_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
